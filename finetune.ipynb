{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T22:19:17.592940Z",
     "start_time": "2024-05-24T22:19:14.733864Z"
    },
    "id": "eDg5XB5XSOvy"
   },
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/hyintell/BLOOM-fine-tuning.git\n",
    "# %cd BLOOM-fine-tuning\n",
    "%cd /mnt/pycharmprojects/cs234_alfred\n",
    "! pip install -r requirements.txt \n",
    "! pip install -U datasets\n",
    "#! pip install fsspec==2023.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T21:33:05.647123Z",
     "start_time": "2024-05-25T21:33:04.923419Z"
    },
    "id": "eDg5XB5XSOvy"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login --token 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 --add-to-git-credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install fsspec==2023.9.2\n",
    "! pip install -U datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs-fO-45SZ7r"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T21:32:57.157503Z",
     "start_time": "2024-05-25T21:32:57.149870Z"
    },
    "id": "Y1K0wM03SUC6"
   },
   "outputs": [],
   "source": [
    "%sql postgresql://alfred:Cc17931793@postgres.diezcansecoramirez.com:5432/lto_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:47:30.514859Z",
     "start_time": "2024-05-25T20:47:25.947237Z"
    },
    "id": "Y1K0wM03SUC6"
   },
   "outputs": [],
   "source": [
    "# insert value using python value\n",
    "comment_value = '098765'\n",
    "#print(df)\n",
    "#%sql UPDATE tapes SET comments='testing' WHERE tag='minio'\n",
    "%sql INSERT INTO tapes(tag, format, comments) VALUES(123456, 'btrfs-snapshot', $comment_value)\n",
    "tapes = %sql SELECT * FROM tapes\n",
    "df = tapes.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0pkIZelS8V6"
   },
   "source": [
    " # Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T21:32:52.417644Z",
     "start_time": "2024-05-25T21:32:52.062223Z"
    },
    "id": "Y1K0wM03SUC6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./venv/lib/python3.10/site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./venv/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./venv/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./venv/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./venv/lib/python3.10/site-packages (from datasets) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./venv/lib/python3.10/site-packages (from datasets) (4.65.0)\n",
      "Requirement already satisfied: xxhash in ./venv/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./venv/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in ./venv/lib/python3.10/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in ./venv/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./venv/lib/python3.10/site-packages (from datasets) (0.23.1)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.10/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext sql\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM, TrainingArguments\n",
    "import psycopg2\n",
    "\n",
    "!pip install -U datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import ModifiedTrainer, tokenise_data, data_collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:12:38.046822Z",
     "start_time": "2024-05-25T03:12:38.040247Z"
    },
    "id": "rYJZvgDGS78C"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:20.373711Z",
     "start_time": "2024-05-25T03:12:42.092986Z"
    },
    "id": "XSVC2chxSTBS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pycharmprojects/cs234_alfred/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bloom-560m\" #1b7\" \n",
    "model = BloomForCausalLM.from_pretrained(f\"bigscience/{model_name}\", torch_dtype=torch.float16).to(device) #, torch_dtype=\"float16\"\n",
    "tokeniser = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:27.057294Z",
     "start_time": "2024-05-25T03:14:20.376870Z"
    },
    "id": "nqfIQ_EQTM3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52002/52002 [00:26<00:00, 1943.46it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('tatsu-lab/alpaca') #, data_files='data/train-00000-of-00001-a09b74b3ef9c3b56.parquet')\n",
    "input_ids = tokenise_data(dataset, tokeniser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "import git\n",
    "from datetime import datetime\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "\n",
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with open(\"logs/BLOOM-fine-tune.log\", \"a\") as f:\n",
    "                sha = repo.head.object.hexsha\n",
    "                logs_add = logs\n",
    "                logs_add[\"git-repository\"] = repo\n",
    "                logs_add[\"git-commit\"] = sha\n",
    "                logs_add[\"date\"] = datetime.now()\n",
    "                f.write(str(logs_add))\n",
    "\n",
    "class DatabaseCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with psycopg2.connect(\n",
    "            open(\"logs/BLOOM-fine-tune.log\", \"a\") as f:\n",
    "                sha = repo.head.object.hexsha\n",
    "                logs_add = logs\n",
    "                logs_add[\"git-repository\"] = repo\n",
    "                logs_add[\"git-commit\"] = sha\n",
    "                logs_add[\"date\"] = datetime.now()\n",
    "                f.write(str(logs_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:40.704193Z",
     "start_time": "2024-05-25T03:14:40.645109Z"
    },
    "id": "j02eVqAoTWsU"
   },
   "outputs": [],
   "source": [
    "from dvclive import Live\n",
    "import os\n",
    "#from utils import PrinterCallback\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "\n",
    "os.environ[\"HF_DVCLIVE_LOG_MODEL\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"output\",\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps= 1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=10,\n",
    "    #report_to=\"dvclive\"\n",
    ")\n",
    "\n",
    "trainer = ModifiedTrainer(\n",
    "    model=model,\n",
    "    train_dataset=input_ids,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[PrinterCallback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:47.540774Z",
     "start_time": "2024-05-25T03:14:47.497524Z"
    },
    "id": "j02eVqAoTWsU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='52002' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   13/52002 00:34 < 44:46:22, 0.32 it/s, Epoch 0.00/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training_args._n_gpu=0\n",
    "# training_args.no_cuda=True\n",
    "# print(training_args)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# with Live(report=\"notebook\") as live:\n",
    "#     live.log_params(training_args)\n",
    "    #for _ in range(training_args[\"num_trains_epochs\"]):\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
