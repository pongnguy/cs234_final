{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T22:19:17.592940Z",
     "start_time": "2024-05-24T22:19:14.733864Z"
    },
    "id": "eDg5XB5XSOvy"
   },
   "source": [
    "# ! git clone https://github.com/hyintell/BLOOM-fine-tuning.git\n",
    "# %cd BLOOM-fine-tuning\n",
    "%cd /mnt/pycharmprojects/cs234_alfred\n",
    "! pip install -r requirements.txt \n",
    "! pip install -U datasets\n",
    "#! pip install fsspec==2023.9.2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T21:33:05.647123Z",
     "start_time": "2024-05-25T21:33:04.923419Z"
    },
    "id": "eDg5XB5XSOvy"
   },
   "source": [
    "!huggingface-cli login --token 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 --add-to-git-credential"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "#! pip install fsspec==2023.9.2\n",
    "! pip install -U datasets"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs-fO-45SZ7r"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T21:32:57.157503Z",
     "start_time": "2024-05-25T21:32:57.149870Z"
    },
    "id": "Y1K0wM03SUC6"
   },
   "source": [
    "%sql postgresql://alfred:Cc17931793@postgres.diezcansecoramirez.com:5432/lto_db"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T20:47:30.514859Z",
     "start_time": "2024-05-25T20:47:25.947237Z"
    },
    "id": "Y1K0wM03SUC6"
   },
   "source": [
    "# insert value using python value\n",
    "comment_value = '098765'\n",
    "#print(df)\n",
    "#%sql UPDATE tapes SET comments='testing' WHERE tag='minio'\n",
    "%sql INSERT INTO tapes(tag, format, comments) VALUES(123456, 'btrfs-snapshot', $comment_value)\n",
    "tapes = %sql SELECT * FROM tapes\n",
    "df = tapes.DataFrame()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0pkIZelS8V6"
   },
   "source": [
    " # Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T21:32:52.417644Z",
     "start_time": "2024-05-25T21:32:52.062223Z"
    },
    "id": "Y1K0wM03SUC6"
   },
   "source": [
    "%load_ext sql\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM, TrainingArguments\n",
    "import psycopg2\n",
    "\n",
    "!pip install -U datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import ModifiedTrainer, tokenise_data, data_collator\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:12:38.046822Z",
     "start_time": "2024-05-25T03:12:38.040247Z"
    },
    "id": "rYJZvgDGS78C"
   },
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = \"cpu\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:20.373711Z",
     "start_time": "2024-05-25T03:12:42.092986Z"
    },
    "id": "XSVC2chxSTBS"
   },
   "source": [
    "model_name = \"bloom-560m\" #1b7\" \n",
    "model = BloomForCausalLM.from_pretrained(f\"bigscience/{model_name}\", torch_dtype=torch.float16).to(device) #, torch_dtype=\"float16\"\n",
    "tokeniser = BloomTokenizerFast.from_pretrained(f\"bigscience/{model_name}\", add_prefix_space=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:27.057294Z",
     "start_time": "2024-05-25T03:14:20.376870Z"
    },
    "id": "nqfIQ_EQTM3f"
   },
   "source": [
    "dataset = load_dataset('tatsu-lab/alpaca') #, data_files='data/train-00000-of-00001-a09b74b3ef9c3b56.parquet')\n",
    "input_ids = tokenise_data(dataset, tokeniser)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "from transformers import TrainerCallback\n",
    "import git\n",
    "from datetime import datetime\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "\n",
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with open(\"logs/BLOOM-fine-tune.log\", \"a\") as f:\n",
    "                sha = repo.head.object.hexsha\n",
    "                logs_add = logs\n",
    "                logs_add[\"git-repository\"] = repo\n",
    "                logs_add[\"git-commit\"] = sha\n",
    "                logs_add[\"date\"] = datetime.now()\n",
    "                f.write(str(logs_add))\n",
    "\n",
    "class DatabaseCallback(TrainerCallback):\n",
    "    repo = git.Repo(search_parent_directories=True)\n",
    "\n",
    "    def __init__(self, *args, host, database, user, password):\n",
    "        super.__init__(self, *args)\n",
    "        self.conn_info = {}\n",
    "        self.conn_info[\"host\"] = host\n",
    "        self.conn_info[\"database\"] = database\n",
    "        self.conn_info[\"user\"] = user\n",
    "        self.conn_info[\"password\"] = password\n",
    "        self.conn = psycopg2.connect(host=self.conn_info[\"host\"], database=self.conn_info[\"database\"], user=self.conn_info[\"user\"], password=self.conn_info[\"password\"])\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with self.conn.cursor() as cur:\n",
    "                cur.execute(f\"INSERT INTO logs (date,git-commit,git-repository,rest) VALUES ('{self.repo}','{self.repo.head.object.hexsha}','{datetime.now()}','{logs}')\")\n",
    "                self.conn.commit()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:40.704193Z",
     "start_time": "2024-05-25T03:14:40.645109Z"
    },
    "id": "j02eVqAoTWsU"
   },
   "source": [
    "from dvclive import Live\n",
    "import os\n",
    "#from utils import PrinterCallback\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model.is_parallelizable = True\n",
    "model.model_parallel = True\n",
    "\n",
    "os.environ[\"HF_DVCLIVE_LOG_MODEL\"] = \"true\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"output\",\n",
    "    fp16=False,\n",
    "    gradient_accumulation_steps= 1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs=2,\n",
    "    logging_steps=10,\n",
    "    #report_to=\"dvclive\"\n",
    ")\n",
    "\n",
    "trainer = ModifiedTrainer(\n",
    "    model=model,\n",
    "    train_dataset=input_ids,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[PrinterCallback, DatabaseCallback(host=\"postgres.diezcansecoramirez.com\", database=\"cs234_db\", user=\"alfred\", password=\"Cc17931793\")],\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T03:14:47.540774Z",
     "start_time": "2024-05-25T03:14:47.497524Z"
    },
    "id": "j02eVqAoTWsU"
   },
   "source": [
    "# training_args._n_gpu=0\n",
    "# training_args.no_cuda=True\n",
    "# print(training_args)\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "# with Live(report=\"notebook\") as live:\n",
    "#     live.log_params(training_args)\n",
    "    #for _ in range(training_args[\"num_trains_epochs\"]):\n",
    "trainer.train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
